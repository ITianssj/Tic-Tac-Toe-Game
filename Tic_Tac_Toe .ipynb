{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f26659",
   "metadata": {},
   "source": [
    "# <center> Tic-Tac-Toe Game with Reinforcement Learning </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66796a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    \"\"\"\n",
    "    A class representing a simple Tic-Tac-Toe game.\n",
    "\n",
    "    Attributes:\n",
    "        board (numpy.ndarray): A 3x3 numpy array representing the game board.\n",
    "        Each cell can be empty (0), marked by 'X' (1), or marked by 'O' (2).\n",
    "        players (list): A list containing the symbols used by the players ('X' and 'O').\n",
    "        current_player (str): The symbol of the player whose turn it currently is.\n",
    "        winner (str): The symbol of the player who has won the game (if any).\n",
    "        game_over (bool): A boolean indicating whether the game has ended.\n",
    "\n",
    "    Methods:\n",
    "        __init__(): Initialize a new Tic-Tac-Toe game with an empty board.\n",
    "        reset(): Reset the game to its initial state.\n",
    "        available_moves(): Get a list of available (empty) positions on the board.\n",
    "        make_move(move): Make a move on the board if it's a valid and available move.\n",
    "        switch_player(): Switch the current player to the other player.\n",
    "        check_winner(): Check if there is a winner and update the `winner` and `game_over` attributes.\n",
    "        print_board(): Print the current state of the game board.\n",
    "\n",
    "    Example Usage:\n",
    "        game = TicTacToe()\n",
    "        game.make_move((0, 0))\n",
    "        game.make_move((1, 1))\n",
    "        game.print_board()\n",
    "        if game.winner:\n",
    "            print(f\"The winner is: {game.winner}\")\n",
    "        elif game.game_over:\n",
    "            print(\"It's a draw!\")\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize a new Tic-Tac-Toe game.\n",
    "\n",
    "        The game starts with an empty 3x3 board, and 'X' always goes first.\n",
    "        \"\"\"\n",
    "        self.board = np.zeros((3, 3))\n",
    "        self.players = ['X', 'O']\n",
    "        self.current_player = None\n",
    "        self.winner = None\n",
    "        self.game_over = False\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the game to its initial state.\n",
    "\n",
    "        This method clears the board, resets the current player, and sets the game status to ongoing.\n",
    "        \"\"\"\n",
    "        self.board = np.zeros((3, 3))\n",
    "        self.current_player = None\n",
    "        self.winner = None\n",
    "        self.game_over = False\n",
    "    \n",
    "    def available_moves(self):\n",
    "         \"\"\"\n",
    "        Get a list of available (empty) positions on the board.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of tuples representing available positions as (row, column).\n",
    "        \"\"\"\n",
    "        moves = []\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.board[i][j] == 0:\n",
    "                    moves.append((i, j))\n",
    "        return moves\n",
    "    \n",
    "    def make_move(self, move):\n",
    "        \"\"\"\n",
    "        Make a move on the board if it's a valid and available move.\n",
    "\n",
    "        Args:\n",
    "            move (tuple): A tuple representing the target position as (row, column).\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the move was successfully made, False otherwise.\n",
    "        \"\"\"\n",
    "        if self.board[move[0]][move[1]] != 0:\n",
    "            return False\n",
    "        self.board[move[0]][move[1]] = self.players.index(self.current_player) + 1\n",
    "        self.check_winner()\n",
    "        self.switch_player()\n",
    "        return True\n",
    "    \n",
    "    def switch_player(self):\n",
    "         \"\"\"\n",
    "        Switch the current player to the other player.\n",
    "        \"\"\"\n",
    "        if self.current_player == self.players[0]:\n",
    "            self.current_player = self.players[1]\n",
    "        else:\n",
    "            self.current_player = self.players[0]\n",
    "    \n",
    "    def check_winner(self):\n",
    "        \"\"\"\n",
    "        Check if there is a winner and update the `winner` and `game_over` attributes.\n",
    "        \"\"\"\n",
    "        # Check rows\n",
    "        for i in range(3):\n",
    "            if self.board[i][0] == self.board[i][1] == self.board[i][2] != 0:\n",
    "                self.winner = self.players[int(self.board[i][0] - 1)]\n",
    "                self.game_over = True\n",
    "        # Check columns\n",
    "        for j in range(3):\n",
    "            if self.board[0][j] == self.board[1][j] == self.board[2][j] != 0:\n",
    "                self.winner = self.players[int(self.board[0][j] - 1)]\n",
    "                self.game_over = True\n",
    "        # Check diagonals\n",
    "        if self.board[0][0] == self.board[1][1] == self.board[2][2] != 0:\n",
    "            self.winner = self.players[int(self.board[0][0] - 1)]\n",
    "            self.game_over = True\n",
    "        if self.board[0][2] == self.board[1][1] == self.board[2][0] != 0:\n",
    "            self.winner = self.players[int(self.board[0][2] - 1)]\n",
    "            self.game_over = True\n",
    "    \n",
    "    def print_board(self):\n",
    "        \"\"\"\n",
    "        Print the current state of the game board.\n",
    "        \"\"\"\n",
    "        print(\"-------------\")\n",
    "        for i in range(3):\n",
    "            print(\"|\", end=' ')\n",
    "            for j in range(3):\n",
    "                print(self.players[int(self.board[i][j] - 1)] if self.board[i][j] != 0 else \" \", end=' | ')\n",
    "            print()\n",
    "            print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TicTacToe game instance\n",
    "game = TicTacToe()\n",
    "\n",
    "# Set the current player to 'X' (Player 1)\n",
    "game.current_player = game.players[0]\n",
    "\n",
    "# Print the initial empty game board\n",
    "game.print_board()\n",
    "\n",
    "# Start the game loop until it's over\n",
    "while not game.game_over:\n",
    "    \n",
    "    # Prompt the current player for their move (row and column)\n",
    "    move = input(f\"{game.current_player}'s turn. Enter row and column (e.g. 0 0): \")\n",
    "    move = tuple(map(int, move.split()))\n",
    "    while move not in game.available_moves():\n",
    "        move = input(\"Invalid move. Try again: \")\n",
    "        move = tuple(map(int, move.split()))\n",
    "    \n",
    "    # Make the valid move on the game board\n",
    "    game.make_move(move)\n",
    "    game.print_board()\n",
    "\n",
    "# Check if there is a winner or if it's a tie\n",
    "if game.winner:\n",
    "    print(f\"{game.winner} wins!\")\n",
    "else:\n",
    "    print(\"It's a tie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class QLearningAgent:\n",
    "    \"\"\"\n",
    "    A class representing a Q-Learning agent for a reinforcement learning task.\n",
    "\n",
    "    Attributes:\n",
    "        Q (dict): A dictionary to store Q-values for state-action pairs.\n",
    "        alpha (float): The learning rate, controlling the impact of new information on Q-values.\n",
    "        epsilon (float): The exploration rate, controlling the probability of taking a random action.\n",
    "        discount_factor (float): The discount factor for future rewards.\n",
    "\n",
    "    Methods:\n",
    "        __init__(self, alpha, epsilon, discount_factor): Initialize a Q-Learning agent with specified parameters.\n",
    "        get_Q_value(self, state, action): Get the Q-value for a specific state-action pair.\n",
    "        choose_action(self, state, available_moves): Choose an action based on Q-values and exploration rate.\n",
    "        update_Q_value(self, state, action, reward, next_state): Update the Q-value for a state-action pair.\n",
    "\n",
    "    Example Usage:\n",
    "        agent = QLearningAgent(alpha=0.1, epsilon=0.2, discount_factor=0.9)\n",
    "        state = current_game_state()\n",
    "        available_moves = get_available_moves(state)\n",
    "\n",
    "        # Choose an action based on Q-values and exploration rate\n",
    "        action = agent.choose_action(state, available_moves)\n",
    "\n",
    "        # Update Q-value based on received reward and the next state\n",
    "        agent.update_Q_value(state, action, reward, next_state)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha, epsilon, discount_factor):\n",
    "        \"\"\"\n",
    "        Initialize a Q-Learning agent.\n",
    "\n",
    "        Args:\n",
    "            alpha (float): The learning rate, controlling the impact of new information on Q-values.\n",
    "            epsilon (float): The exploration rate, controlling the probability of taking a random action.\n",
    "            discount_factor (float): The discount factor for future rewards.\n",
    "        \"\"\"\n",
    "        self.Q = {}\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.discount_factor = discount_factor\n",
    "\n",
    "    def get_Q_value(self, state, action):\n",
    "        \"\"\"\n",
    "        Get the Q-value for a specific state-action pair.\n",
    "\n",
    "        Args:\n",
    "            state (hashable): The current state.\n",
    "            action (hashable): The action taken in the current state.\n",
    "\n",
    "        Returns:\n",
    "            float: The Q-value for the given state-action pair.\n",
    "        \"\"\"\n",
    "        if (state, action) not in self.Q:\n",
    "            self.Q[(state, action)] = 0.0\n",
    "        return self.Q[(state, action)]\n",
    "\n",
    "    def choose_action(self, state, available_moves):\n",
    "        \"\"\"\n",
    "        Choose an action based on Q-values and exploration rate.\n",
    "\n",
    "        Args:\n",
    "            state (hashable): The current state.\n",
    "            available_moves (list): A list of available actions in the current state.\n",
    "\n",
    "        Returns:\n",
    "            hashable: The chosen action.\n",
    "        \"\"\"\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(available_moves)\n",
    "        else:\n",
    "            Q_values = [self.get_Q_value(state, action) for action in available_moves]\n",
    "            max_Q = max(Q_values)\n",
    "            if Q_values.count(max_Q) > 1:\n",
    "                best_moves = [i for i in range(len(available_moves)) if Q_values[i] == max_Q]\n",
    "                i = random.choice(best_moves)\n",
    "            else:\n",
    "                i = Q_values.index(max_Q)\n",
    "            return available_moves[i]\n",
    "\n",
    "    def update_Q_value(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        Update the Q-value for a state-action pair.\n",
    "\n",
    "        Args:\n",
    "            state (hashable): The current state.\n",
    "            action (hashable): The action taken in the current state.\n",
    "            reward (float): The reward received for taking the action.\n",
    "            next_state (hashable): The resulting state after taking the action.\n",
    "        \"\"\"\n",
    "        next_Q_values = [self.get_Q_value(next_state, next_action) for next_action in TicTacToe(next_state).available_moves()]\n",
    "        max_next_Q = max(next_Q_values) if next_Q_values else 0.0\n",
    "        self.Q[(state, action)] += self.alpha * (reward + self.discount_factor * max_next_Q - self.Q[(state, action)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3700e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_episodes, alpha, epsilon, discount_factor):\n",
    "     \"\"\"\n",
    "    Train a Q-Learning agent by playing Tic-Tac-Toe episodes.\n",
    "\n",
    "    Args:\n",
    "        num_episodes (int): The number of episodes (games) to play for training.\n",
    "        alpha (float): The learning rate for updating Q-values.\n",
    "        epsilon (float): The exploration rate, controlling random actions during training.\n",
    "        discount_factor (float): The discount factor for future rewards.\n",
    "\n",
    "    Returns:\n",
    "        QLearningAgent: A trained Q-Learning agent.\n",
    "    \"\"\"\n",
    "    agent = QLearningAgent(alpha, epsilon, discount_factor)\n",
    "    for i in range(num_episodes):\n",
    "        state = TicTacToe().board\n",
    "        while not TicTacToe(state).game_over():\n",
    "            available_moves = TicTacToe(state).available_moves()\n",
    "            action = agent.choose_action(state, available_moves)\n",
    "            next_state, reward = TicTacToe(state).make_move(action)\n",
    "            agent.update_Q_value(state, action, reward, next_state)\n",
    "            state = next_state\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97727ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent, num_games):\n",
    "    \"\"\"\n",
    "    Test a trained Q-Learning agent by playing Tic-Tac-Toe games.\n",
    "\n",
    "    Args:\n",
    "        agent (QLearningAgent): A trained Q-Learning agent.\n",
    "        num_games (int): The number of games to play for testing.\n",
    "\n",
    "    Returns:\n",
    "        float: The win percentage of the agent in the test games.\n",
    "    \"\"\"\n",
    "    num_wins = 0\n",
    "    for i in range(num_games):\n",
    "        state = TicTacToe().board\n",
    "        while not TicTacToe(state).game_over():\n",
    "            if TicTacToe(state).player == 1:\n",
    "                action = agent.choose_action(state, TicTacToe(state).available_moves())\n",
    "            else:\n",
    "                action = random.choice(TicTacToe(state).available_moves())\n",
    "            state, reward = TicTacToe(state).make_move(action)\n",
    "        if reward == 1:\n",
    "            num_wins += 1\n",
    "    return num_wins / num_games * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742265b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Q-learning agent\n",
    "agent = train(num_episodes=100000, alpha=0.5, epsilon=0.1, discount_factor=1.0)\n",
    "\n",
    "# Test the Q-learning agent\n",
    "win_percentage = test(agent, num_games=1000)\n",
    "print(\"Win percentage: {:.2f}%\".format(win_percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a344c303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
